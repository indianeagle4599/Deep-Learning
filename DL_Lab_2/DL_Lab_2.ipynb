{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsaULBmmxnLL"
      },
      "source": [
        "# Creating our own Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zp-yvguwsRQh"
      },
      "source": [
        "## Creating a simple Neural Network with One input and One output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRxwc1kwNbDE"
      },
      "outputs": [],
      "source": [
        "wt = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1LsgGDjUJPs"
      },
      "outputs": [],
      "source": [
        "def neural_network(ip, wt):\n",
        "  pred = ip*wt\n",
        "  return pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eTLnDVIZUWtg"
      },
      "outputs": [],
      "source": [
        "num_of_centuries = [2, 4, 1, 15]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LmcaL_P0V5u3"
      },
      "outputs": [],
      "source": [
        "pred = neural_network(num_of_centuries[0], wt)\n",
        "pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DdK_7Drsivz"
      },
      "source": [
        "## Creating a Neural Network with Multiple inputs and One output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--FwUuESVEIH"
      },
      "outputs": [],
      "source": [
        "wts = [0.2, 0.4, 1.0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KF9mQN6eWL3o"
      },
      "outputs": [],
      "source": [
        "def w_sum(l1, l2):\n",
        "  sum = 0\n",
        "  if len(l1) == len(l2):\n",
        "    for i in range(len(l1)):\n",
        "      sum += l1[i]*l2[i]\n",
        "  else:\n",
        "    print('Incorrect input sizes.')\n",
        "    print(l1)\n",
        "    print(l2)\n",
        "  return sum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKeNHOvCVUT4"
      },
      "outputs": [],
      "source": [
        "def neural_network(ip, wt):\n",
        "  pred = w_sum(ip, wt)\n",
        "  return pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38gUTuRAVeKk"
      },
      "outputs": [],
      "source": [
        "num_of_centuries = [2, 4, 1, 15]\n",
        "num_of_matches = [10, 12, 10, 25]\n",
        "num_of_overs = [50, 70, 40, 120]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJV8CAuRV7gL"
      },
      "outputs": [],
      "source": [
        "ip = [num_of_centuries[0], num_of_matches[0], num_of_overs[0]]\n",
        "pred = neural_network(ip, wts)\n",
        "pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjyPObYGxNnG"
      },
      "source": [
        "### Using Numpy to create a Neural Network with Multiple inputs and One output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1MvNLX9qmiwH"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "baia5FBvoT1q"
      },
      "outputs": [],
      "source": [
        "def neural_network(ip, wt):\n",
        "  pred = np.dot(ip, wt)\n",
        "  return pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8qhAG5uynnTq"
      },
      "outputs": [],
      "source": [
        "wts = np.array(wts)\n",
        "num_of_centuries = np.array(num_of_centuries)\n",
        "num_of_matches = np.array(num_of_matches)\n",
        "num_of_overs = np.array(num_of_overs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBDyJIJYoHRq"
      },
      "outputs": [],
      "source": [
        "ip = np.array([num_of_centuries[0], num_of_matches[0], num_of_overs[0]])\n",
        "pred = neural_network(ip, wts)\n",
        "pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbF72unLxIrK"
      },
      "source": [
        "## Trying some vector operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bAPFMVH3WHwj"
      },
      "outputs": [],
      "source": [
        "def elemwiseMul(a, b):\n",
        "  sum = []\n",
        "\n",
        "  # Make sure a is the bigger of the two vectors\n",
        "  if len(a) > len(b):\n",
        "    temp = a\n",
        "    a = b\n",
        "    b = a\n",
        "  \n",
        "  for i in range(len(a)):\n",
        "    if i < len(b):\n",
        "      sum.append(a[i]*b[i])\n",
        "    else:\n",
        "      sum.append(0)\n",
        "  \n",
        "  return sum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7r29hoek80x"
      },
      "outputs": [],
      "source": [
        "def elemwiseSum(a, b):\n",
        "  sum = []\n",
        "\n",
        "  # Make sure a is the bigger of the two vectors\n",
        "  if len(a) > len(b):\n",
        "    temp = a\n",
        "    a = b\n",
        "    b = a\n",
        "  \n",
        "  for i in range(len(a)):\n",
        "    if i < len(b):\n",
        "      sum.append(a[i]+b[i])\n",
        "    else:\n",
        "      sum.append(a[i])\n",
        "  \n",
        "  return sum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6_uDYA0lr40"
      },
      "outputs": [],
      "source": [
        "def vecSum(a):\n",
        "  sum = 0\n",
        "  for i in a:\n",
        "    sum += i\n",
        "  return sum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IFMiztbGmTGS"
      },
      "outputs": [],
      "source": [
        "def vecAvg(a):\n",
        "  sum = 0\n",
        "  for i in a:\n",
        "    sum += i\n",
        "  return sum/len(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GIfAekd8ksH_"
      },
      "outputs": [],
      "source": [
        "elemwiseMul(num_of_centuries, num_of_matches)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XpOSptt-lof5"
      },
      "outputs": [],
      "source": [
        "elemwiseSum(num_of_centuries, num_of_matches)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMPSQejXmP09"
      },
      "outputs": [],
      "source": [
        "vecSum(num_of_centuries)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "myhGfYDZmgVD"
      },
      "outputs": [],
      "source": [
        "vecAvg(num_of_centuries)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abYzDEkOxTib"
      },
      "source": [
        "## Creating a Neural Network with One input Multiple outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-TgZoQhri18"
      },
      "outputs": [],
      "source": [
        "def scaleVecMul(ip, wts):\n",
        "  pred = []\n",
        "  for i in wts:\n",
        "    pred.append(ip*i)\n",
        "  return pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQPbrJfhomXK"
      },
      "outputs": [],
      "source": [
        "def neural_network(ip, wts):\n",
        "  pred = scaleVecMul(ip, wts)\n",
        "  return pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o0doJlO5dGi8"
      },
      "outputs": [],
      "source": [
        "ip = num_of_centuries[0]\n",
        "ip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HwnlQe8ndIUR"
      },
      "outputs": [],
      "source": [
        "wts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wR7onuS6pvZQ"
      },
      "outputs": [],
      "source": [
        "neural_network(ip, wts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJLYZcN3yO6S"
      },
      "source": [
        "## Creating a Neural Network with Multiple inputs Multiple outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1yTrB2O_u2m"
      },
      "source": [
        "### Creating the neural network with for loops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VmK1rrwHp-r4"
      },
      "outputs": [],
      "source": [
        "# 3 input layers and 4 output layers\n",
        "wts = [[10, 5, 0.2],\n",
        "       [2, 8, 5],\n",
        "       [0.5, 0.9, 2.2],\n",
        "       [10, 8, 0.9]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhV7LRgUtul3"
      },
      "outputs": [],
      "source": [
        "def neural_network(ip, wts):\n",
        "  pred = []\n",
        "  for i in wts:\n",
        "    pred.append(w_sum(ip, i))\n",
        "  return pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HAvxvE7PcZMu"
      },
      "outputs": [],
      "source": [
        "ip = [num_of_centuries[0], num_of_matches[0], num_of_overs[0]]\n",
        "ip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GbOyjsfCvg2x"
      },
      "outputs": [],
      "source": [
        "neural_network(ip, wts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEwf70btyA0v"
      },
      "source": [
        "### Numpy function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFO15WOYriPO"
      },
      "outputs": [],
      "source": [
        "np.array(ip).dot(np.array(wts).T)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4ebGYyKxuHU"
      },
      "source": [
        "## Creating a Multiple Layer Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXIYrG1o_lPP"
      },
      "source": [
        "### Creating the deep neural network with for loops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kkz_nzpPx159"
      },
      "outputs": [],
      "source": [
        "# 3 inputs and 4 outputs\n",
        "wts_l1 = [[42, 7, 9.5],\n",
        "          [7, 2, 4],\n",
        "          [7.1, 3.8, 1.8],\n",
        "          [10, 8, 0.9]]\n",
        "\n",
        "# 4 inputs and 5 outputs\n",
        "wts_l2 =  [[10, 5, 0.2, 42],\n",
        "           [5, 0.5, 2, 2],\n",
        "           [2, 8, 5, 3.8],\n",
        "           [0.5, 0.9, 2.2, 0.9],\n",
        "           [7, 2, 4, 8]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-5tM12rzN0O"
      },
      "outputs": [],
      "source": [
        "def layer(ip, wts):\n",
        "  lay = []\n",
        "  for i in wts:\n",
        "    lay.append(w_sum(ip, i))\n",
        "  return lay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6CI0CeXRysCy"
      },
      "outputs": [],
      "source": [
        "def neural_network(ip, wts_l1, wts_l2):\n",
        "  hid = layer(ip, wts_l1)\n",
        "  pred = layer(hid, wts_l2)\n",
        "  return pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCzmYm0EzpYe"
      },
      "outputs": [],
      "source": [
        "neural_network(ip, wts_l1, wts_l2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DgNF1ClaCbH"
      },
      "source": [
        "### Using Numpy to create the same Deep Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0nTxUaBE0c1s"
      },
      "outputs": [],
      "source": [
        "wts_l1 = np.array(wts_l1)\n",
        "wts_l2 = np.array(wts_l2)\n",
        "ip = np.array([num_of_centuries[0], num_of_matches[0], num_of_overs[0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_AK_lcmfaoYC"
      },
      "outputs": [],
      "source": [
        "def neural_network(ip, wts_l1, wts_l2):\n",
        "  hid = ip.dot(wts_l1.T)\n",
        "  pred = hid.dot(wts_l2.T)\n",
        "  return pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a70k7O7IbCWQ"
      },
      "outputs": [],
      "source": [
        "neural_network(ip, wts_l1, wts_l2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwLV9ygDyVTd"
      },
      "source": [
        "# Creating Gradient Descent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxwGjWxtyb84"
      },
      "source": [
        "## Comparison for error calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kW0gHHeLzeZt"
      },
      "outputs": [],
      "source": [
        "def neural_network(ip, wt):\n",
        "  pred = ip*wt\n",
        "  return pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tuhvifSLyYP3"
      },
      "outputs": [],
      "source": [
        "def compare(wt, ip, act):\n",
        "  pred = neural_network(ip, wt)\n",
        "  error = (pred-act)**2 # Square error\n",
        "  return error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fHdwKAt2y2bL"
      },
      "outputs": [],
      "source": [
        "wt, ip = 0.2, 20 # Prediction is 4\n",
        "act = 5.2\n",
        "\n",
        "compare(wt, ip, act)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ux5DrURg0kTk"
      },
      "source": [
        "## Comparison and error reduction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Di9qR-_gy43I"
      },
      "outputs": [],
      "source": [
        "def compare(wt, ip, act, lr):\n",
        "  pred = neural_network(ip, wt)\n",
        "  error = (pred-act)**2\n",
        "\n",
        "  # Increasing the weight\n",
        "  pred_up = neural_network(ip, wt+lr)\n",
        "  err_up = (pred_up - act)**2\n",
        "\n",
        "  # Decreasing the weight\n",
        "  pred_dn = neural_network(ip, wt-lr)\n",
        "  err_dn = (pred_dn - act)**2\n",
        "\n",
        "  if error > err_up or error > err_dn:\n",
        "    if err_up < err_dn:\n",
        "      wt += lr\n",
        "    else:\n",
        "      wt -= lr\n",
        "\n",
        "  fin_pred = neural_network(ip, wt)\n",
        "  fin_err = (fin_pred-act)**2\n",
        "  \n",
        "  return wt, fin_err # Returning the final weight and the error at that weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oag40dKk2H86"
      },
      "outputs": [],
      "source": [
        "wt, ip = 0.2, 20 # Prediction is 4\n",
        "act = 6\n",
        "lr = 0.002\n",
        "\n",
        "compare(wt, ip, act, lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOGe0vBL3NZI"
      },
      "source": [
        "## Comparison, Error reduction and Weight Manipulation (Learning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRoJE9XNgPP8"
      },
      "source": [
        "### Hot an Cold Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Zo5Xzmr2nVk"
      },
      "outputs": [],
      "source": [
        "def learn(wt, ip, act, lr, iters):\n",
        "  wt_vals = []\n",
        "  err_vals = []\n",
        "  for i in range(iters):\n",
        "    nwt, nerror = compare(wt, ip, act, lr)\n",
        "    wt_vals.append(nwt)\n",
        "    err_vals.append(nerror)\n",
        "    if nwt != wt:\n",
        "      wt, error = nwt, nerror\n",
        "      print(f'{i+1}.\\tNew weight : {round(wt, 3)}\\tNew error: {error}')\n",
        "    else:\n",
        "      print('Convergence reached')\n",
        "      break\n",
        "  return wt, error, [wt_vals, err_vals]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zF_7UPWz3vKl"
      },
      "outputs": [],
      "source": [
        "wt, ip = 0.2, 20 # Prediction is 4\n",
        "act = 6\n",
        "lr, iters = 0.02, 10\n",
        "\n",
        "fin_wt, fin_err, wt_err_vals = learn(wt, ip, act, lr, iters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4vq-1oiA30Tf"
      },
      "outputs": [],
      "source": [
        "neural_network(ip, fin_wt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AlrcwmAmne4"
      },
      "source": [
        "#### Plotting the error change with respect to weight change"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92sH7uqolLOj"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGSUn3vOlOk4"
      },
      "outputs": [],
      "source": [
        "plt.plot(wt_err_vals[0], wt_err_vals[1])\n",
        "plt.scatter(wt_err_vals[0], wt_err_vals[1])\n",
        "plt.xlabel('Weights')\n",
        "plt.ylabel('Error')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aKP08U6mux8"
      },
      "source": [
        "Take notice of the fact that the distribution is quite uniform. The model moves quite evenly down the error curve."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Yhtd6VJgX2W"
      },
      "source": [
        "*Even so, we can consider oursleves lucky for our value to have converged because this is a very inefficient way when predicting values where the minima isn't a multiple of the learning rate. We usually get a close point which isn't the best one.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCRxF9xXgSYr"
      },
      "source": [
        "### The Better Way"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZWOy9hRz5JBh"
      },
      "outputs": [],
      "source": [
        "def compare(wt, ip, act, lr):\n",
        "  pred = neural_network(ip, wt)\n",
        "  pure_error = pred-act\n",
        "  scaled_error = pure_error*ip*lr\n",
        "  wt -= scaled_error # Change the weight depending on the error\n",
        "\n",
        "  pred = neural_network(ip, wt)\n",
        "  error = (pred-act)**2\n",
        "  \n",
        "  return wt, error # Returning the final weight and the error at that weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ruOcZAyhacd"
      },
      "outputs": [],
      "source": [
        "wt, ip = 0, 20 # Prediction is 4\n",
        "act = 6\n",
        "lr, iters = 0.002, 100\n",
        "\n",
        "fin_wt, fin_err, wt_err_vals = learn(wt, ip, act, lr, iters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSQcYR92hd3k"
      },
      "outputs": [],
      "source": [
        "neural_network(ip, fin_wt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zq_X0qXsixyX"
      },
      "source": [
        "It has definitely taken longer to converge but that is only because the rate of change starts to reduce when we reach closer to the actual value. This is because the error between the prediction and actual value starts to drop causing the scaled error value to also drop."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wb3FLICnpot"
      },
      "source": [
        "#### Plotting the error change with respect to weight change"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4A-fJkXpkCGS"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20, 4))\n",
        "plt.plot(wt_err_vals[0], wt_err_vals[1])\n",
        "plt.scatter(wt_err_vals[0], wt_err_vals[1])\n",
        "plt.xlabel('Weights')\n",
        "plt.ylabel('Error')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMZX25HenqjM"
      },
      "source": [
        "We can see the phenomenon here. The distance between the two points seems to be very huge in the beginning and it seems to reduce as we progress. we can practically see only 6-7 points when we actually converged after about 20-25 iterations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNml5DREWwAF"
      },
      "source": [
        "## Applying Gradient Descent on a set of datapoints"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZyZQ8E-31uo"
      },
      "source": [
        "### Standard approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vPF22U4GXiSP"
      },
      "outputs": [],
      "source": [
        " def compare(wt, ips, acts, lr):\n",
        "  for i in range(len(ips)):\n",
        "    pred = neural_network(ips[i], wt)\n",
        "    pure_error = pred-acts[i]\n",
        "    scaled_error = pure_error*ips[i]*lr\n",
        "    wt -= scaled_error # Change the weight depending on the error\n",
        "  return wt, getMAE(ips, acts, wt)\n",
        "\n",
        "def getMAE(ips, acts, wt):\n",
        "  error = 0\n",
        "  for i in range(len(ips)):\n",
        "    pred = neural_network(ips[i], wt)\n",
        "    error += abs(pred-acts[i])\n",
        "  return error / len(ips)\n",
        "\n",
        "def learn(wt, ip, act, lr, iters):\n",
        "  wt_vals = []\n",
        "  err_vals = []\n",
        "  for i in range(iters):\n",
        "    nwt, nerror = compare(wt, ip, act, lr)\n",
        "    wt_vals.append(nwt)\n",
        "    err_vals.append(nerror)\n",
        "    if nwt != wt:\n",
        "      wt, error = nwt, nerror\n",
        "      print(f'{i+1}.\\tNew weight : {round(wt, 5)}\\tNew error: {error}')\n",
        "    else:\n",
        "      print('Convergence reached')\n",
        "      break\n",
        "  return wt, error, [wt_vals, err_vals]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tQj62QMW41y"
      },
      "outputs": [],
      "source": [
        "ip = [1, 3, 5, 7, 9]\n",
        "act = [5, 16, 24, 38, 45] # y = 5x\n",
        "iters = 100\n",
        "lr = 0.01\n",
        "wt = -5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iF2NooIMagqL"
      },
      "outputs": [],
      "source": [
        "fin_wt, fin_err, wt_err_vals = learn(wt, ip, act, lr, iters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iwHbUGXSa_wm"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(25, 5))\n",
        "plt.plot(wt_err_vals[0], wt_err_vals[1])\n",
        "plt.scatter(wt_err_vals[0], wt_err_vals[1])\n",
        "plt.xlabel('Weights')\n",
        "plt.ylabel('Error')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nuWBTUhA1y0w"
      },
      "outputs": [],
      "source": [
        "getMAE(ip, act, fin_wt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixhjP-wruM2Q"
      },
      "source": [
        "We can quite clearly see the problem of overlearning above. Our best weight is just less than 5 but we shoot up because the learning rate is not rescaled. We can try to add a dynamic learning rate which can take car eof that issue for us."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsSVhbDH-Qr_"
      },
      "source": [
        "### Exploring a dynamic Learning Rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7K7x9gdh6cS"
      },
      "outputs": [],
      "source": [
        "def learn(wt, ip, act, lr, iters):\n",
        "  wt_vals = []\n",
        "  err_vals = []\n",
        "  # Consider the first weights to be the best ones\n",
        "  best_wt, min_error = compare(wt, ip, act, 0)\n",
        "  tol = 0\n",
        "  perfection = 16\n",
        "  change_factor = 2\n",
        "\n",
        "  for i in range(iters):\n",
        "    nwt, nerror = compare(best_wt, ip, act, lr)\n",
        "    # If we find out that the best weights are better than the current ones\n",
        "    if min_error < nerror:\n",
        "      if round(lr, perfection) > 0:\n",
        "        # Reduce the learning rate without changing the weights\n",
        "        lr /= change_factor\n",
        "        nwt, nerror = best_wt, min_error\n",
        "        print(f'---------------------------------------------------------\\nReduced learning rate to avoid overlearning. New value: {lr}\\n---------------------------------------------------------')\n",
        "        tol = 0\n",
        "\n",
        "    # If the new error is lesser than the current one\n",
        "    elif min_error > nerror:\n",
        "      if round(min_error, perfection) == round(nerror, perfection):\n",
        "        lr *= change_factor\n",
        "        print(f'---------------------------------------------------------\\nIncreased learning rate to avoid underlearning. New value: {lr}\\n---------------------------------------------------------')\n",
        "      else:\n",
        "        best_wt, min_error = nwt, nerror\n",
        "        print(f'{i+1}.\\tNew weight : {round(best_wt, 5)}\\tNew error: {min_error}')\n",
        "        tol = 0\n",
        "        wt_vals.append(best_wt)\n",
        "        err_vals.append(min_error)\n",
        "    \n",
        "    # If the new error is equal to the current one and no learning rate value helps\n",
        "    else:\n",
        "      if tol > iters/10:\n",
        "        print('Convergence reached')\n",
        "        break\n",
        "      else:\n",
        "        tol += 1\n",
        "  return best_wt, min_error, [wt_vals, err_vals]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMKT2AoEwvx-"
      },
      "outputs": [],
      "source": [
        "ip = [1, 3, 5, 7, 9]\n",
        "act = [5, 16, 24, 38, 45] # y = 5x\n",
        "iters = 100\n",
        "lr = 5.12\n",
        "wt = -5\n",
        "\n",
        "fin_wt, fin_err, wt_err_vals = learn(wt, ip, act, lr, iters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YAmkJU3lwyOz"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(25, 5))\n",
        "plt.plot(wt_err_vals[0], wt_err_vals[1])\n",
        "plt.scatter(wt_err_vals[0], wt_err_vals[1])\n",
        "plt.xlabel('Weights')\n",
        "plt.ylabel('Error')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_Q1nC_cx4Fb"
      },
      "outputs": [],
      "source": [
        "getMAE(ip, act, fin_wt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3icILh61wiA"
      },
      "outputs": [],
      "source": [
        "ip = [1, 3, 5, 7, 9]\n",
        "act = [5, 16, 24, 38, 45] # y = 5x\n",
        "iters = 100\n",
        "lr = 0.01\n",
        "wt = -5\n",
        "\n",
        "fin_wt, fin_err, wt_err_vals = learn(wt, ip, act, lr, iters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXfS8efa3G-_"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(25, 5))\n",
        "plt.plot(wt_err_vals[0], wt_err_vals[1])\n",
        "plt.scatter(wt_err_vals[0], wt_err_vals[1])\n",
        "plt.xlabel('Weights')\n",
        "plt.ylabel('Error')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XCje_hwU3JC-"
      },
      "outputs": [],
      "source": [
        "getMAE(ip, act, fin_wt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfqfFLwZ-z8h"
      },
      "source": [
        "From the two different values of learning rate, we can see clearly that it is very important to choose the right value for learning rate to minimise error as much as possible. Even a mutliple of the best learning rate doesn't always ensure the best result. In any case, we can be sure to get a better result by making the learning rate dynamic which is better than nothing."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Zp-yvguwsRQh",
        "2DdK_7Drsivz",
        "EbF72unLxIrK",
        "abYzDEkOxTib",
        "xJLYZcN3yO6S",
        "pEwf70btyA0v",
        "O4ebGYyKxuHU",
        "3DgNF1ClaCbH"
      ],
      "name": "DL Lab 2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
